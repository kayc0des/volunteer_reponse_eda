{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "o0nIbzNCK1P4"
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5sxhnMdJyHp"
   },
   "source": [
    "## Preliminary Data Inspection\n",
    "\n",
    "This class is designed to streamline the initial exploration and quality assessment of a daraset. Providing methods like loading the datatset, inspecting the structure, previewing, identifying missing values and detecting duplicates.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8gJ6w0T6NqyS"
   },
   "outputs": [],
   "source": [
    "class PreliminaryDataInspection():\n",
    "    '''\n",
    "    This class performs preliminary data inspection.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, df=None, file_path=None, sep=\",\"):\n",
    "        '''\n",
    "        Initializes the class by assigning a DataFrame or loading it from a file.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame, optional): DataFrame to initialize the class with.\n",
    "            file_path (str, optional): Path to the data file.\n",
    "            sep (str, optional): Separator used in the file. Default is \",\".\n",
    "        '''\n",
    "        if df is not None and isinstance(df, pd.DataFrame):\n",
    "            self.df = df\n",
    "            print(\"DataFrame provided directly.\")\n",
    "        elif file_path is not None:\n",
    "            self.df = self.load_data(file_path, sep)\n",
    "        else:\n",
    "            self.df = None\n",
    "            print(\"No valid DataFrame or file path provided.\")\n",
    "\n",
    "    def load_data(self, file_path, sep=\",\"):\n",
    "        '''\n",
    "        Loads a data file and returns a DataFrame.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the data file.\n",
    "            sep (str): Separator used in the file. Default is \",\".\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame or None: The loaded DataFrame or None if file not found.\n",
    "        '''\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep)\n",
    "            print(f\"Data successfully loaded from {file_path}.\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return None\n",
    "\n",
    "    def check_info(self):\n",
    "        '''\n",
    "        Displays information about the DataFrame.\n",
    "        '''\n",
    "        if self.df is not None:\n",
    "            print(\"DataFrame Info:\")\n",
    "            print(self.df.info())\n",
    "        else:\n",
    "            print(\"No DataFrame to inspect.\")\n",
    "\n",
    "    def check_head(self, n=5):\n",
    "        '''\n",
    "        Displays the first few rows of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            n (int): Number of rows to display. Default is 5.\n",
    "        '''\n",
    "        if self.df is not None:\n",
    "            print(f\"First {n} rows of the DataFrame:\")\n",
    "            print(self.df.head(n))\n",
    "        else:\n",
    "            print(\"No DataFrame to inspect.\")\n",
    "\n",
    "    def check_missing_values(self):\n",
    "        '''\n",
    "        Checks for missing values in the DataFrame.\n",
    "        '''\n",
    "        if self.df is not None:\n",
    "            print(\"Missing Values in DataFrame:\")\n",
    "            missing_values = self.df.isnull().sum()\n",
    "            print(missing_values[missing_values > 0])\n",
    "        else:\n",
    "            print(\"No DataFrame to inspect.\")\n",
    "\n",
    "    def check_duplicates(self):\n",
    "        '''\n",
    "        Checks for duplicate rows in the DataFrame.\n",
    "        '''\n",
    "        if self.df is not None:\n",
    "            duplicates = self.df.duplicated().sum()\n",
    "            print(f\"Number of duplicate rows: {duplicates}\")\n",
    "        else:\n",
    "            print(\"No DataFrame to inspect.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wf-hiv2LPTX_"
   },
   "source": [
    "### Alarm Response (`Alarmresponses.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N5dXq-RUPSCt",
    "outputId": "5ee0d5de-b666-45f5-8ae5-0b6c5720b3db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from data/Alarmresponses.txt.\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4124815 entries, 0 to 4124814\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Dtype \n",
      "---  ------        ----- \n",
      " 0   alarmid       int64 \n",
      " 1   userid        int64 \n",
      " 2   DeviceType    int64 \n",
      " 3   devices       object\n",
      " 4   Response      int64 \n",
      " 5   ResponseDate  object\n",
      " 6   latitude      object\n",
      " 7   longitude     object\n",
      "dtypes: int64(4), object(4)\n",
      "memory usage: 251.8+ MB\n",
      "None\n",
      "First 5 rows of the DataFrame:\n",
      "   alarmid               userid  DeviceType devices  Response ResponseDate  \\\n",
      "0    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "1    79629  2210044967363094894           4     Sms         0          NaN   \n",
      "2    82395  2210044967363094894           4     Sms         0          NaN   \n",
      "3    89313  2210044967363094894           4     Sms         0          NaN   \n",
      "4    43918   738033312678202846           4     Sms         0          NaN   \n",
      "\n",
      "           latitude         longitude  \n",
      "0  51,9987411499023  4,77543687820435  \n",
      "1  51,9987411499023  4,77543687820435  \n",
      "2  51,9987411499023  4,77543687820435  \n",
      "3  51,9987411499023  4,77543687820435  \n",
      "4        53,2114995         5,7695914  \n",
      "Missing Values in DataFrame:\n",
      "devices             193\n",
      "ResponseDate    3603938\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "alarm_response = PreliminaryDataInspection('data/Alarmresponses.txt', sep='\\t')\n",
    "\n",
    "alarm_response.check_info()\n",
    "alarm_response.check_head()\n",
    "alarm_response.check_missing_values()\n",
    "alarm_response.check_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APC2-k_SQh-N"
   },
   "source": [
    "### Data Summary:\n",
    "\n",
    "Alarm reponses contains 4,124,815 entries with 8 columns (4214815 x 8 matrix), the columns are:\n",
    "\n",
    "- alarmid: Unique identifier for each alarm event (integer).\n",
    "- userid: Unique identifier for the user who triggered the alarm (integer).\n",
    "- DeviceType: Type of device used to trigger the alarm (integer).\n",
    "- devices: Description of the device used (object). 193 entries are missing values.\n",
    "- Response: Indicates if a volunteer responded to the alarm (0 - no response, 1 - responded) (integer).\n",
    "- ResponseDate: Date and time the volunteer responded (object). 3,603,938 entries are missing values.\n",
    "- latitude: Latitude coordinate of the alarm location (object).\n",
    "- longitude: Longitude coordinate of the alarm location (object).\n",
    "\n",
    "**Data Insights:**\n",
    "\n",
    "- A large portion of the data (over 87%) has missing values in the RespinseDate column. As at now, no conclusion could be made regarding the missing date values. Depending on its correlation with the target variable, I might result to dropping the column if it is negatively correlated with the Response column.\n",
    "\n",
    "- There are missing values in the devices column, indicating some descriptions of the triggering devices are unavailable.\n",
    "\n",
    "- The data seems suitable for analyzing volunteer response patterns, effectiveness, and identifying areas for improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJYX4KbqSh24"
   },
   "source": [
    "### Alarms (`Alarms.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4wKRYIhcSnHN",
    "outputId": "7ab45811-f802-410a-abed-def71e5c8cd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from data/Alarms.txt.\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60329 entries, 0 to 60328\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   alarmid         60329 non-null  int64 \n",
      " 1   alarmlocaltime  60329 non-null  object\n",
      " 2   Latitude        60329 non-null  object\n",
      " 3   Longitude       60329 non-null  object\n",
      " 4   AlarmStatus     60329 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "First 5 rows of the DataFrame:\n",
      "   alarmid           alarmlocaltime   Latitude Longitude  AlarmStatus\n",
      "0    29977  2020-01-01 00:23:14.200   52,26168  5,603156            1\n",
      "1    29979  2020-01-01 00:25:36.730  51,900643  4,484577            1\n",
      "2    29980  2020-01-01 00:34:54.213   52,63205  4,726312            1\n",
      "3    29982  2020-01-01 00:58:24.897  51,263437  4,045439            1\n",
      "4    29983  2020-01-01 00:59:01.363  51,334741  6,129295            1\n",
      "Missing Values in DataFrame:\n",
      "Series([], dtype: int64)\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "alarms = PreliminaryDataInspection('data/Alarms.txt', sep='\\t')\n",
    "\n",
    "alarms.check_info()\n",
    "alarms.check_head()\n",
    "alarms.check_missing_values()\n",
    "alarms.check_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCFoKlCmTqD1"
   },
   "source": [
    "### Data Summary:\n",
    "\n",
    "The data is stored in a pandas DataFrame containing 60,329 entries. There are 5 columns in the DataFrame:\n",
    "- alarmid: Unique identifier for each alarm event (integer).\n",
    "- alarmlocaltime: Local time of the alarm event (object).\n",
    "- Latitude: Latitude coordinate of the alarm location (object).\n",
    "- Longitude: Longitude coordinate of the alarm location (object).\n",
    "- AlarmStatus: Status of the alarm (integer, likely indicating active/inactive).\n",
    "\n",
    "**Data Insights:**\n",
    "\n",
    "- The data has no missing values.\n",
    "- The alarmlocaltime column contains timestamp information, which can be useful for temporal analysis.\n",
    "- The Latitude and Longitude columns provide geographic information, enabling spatial analysis.\n",
    "- The AlarmStatus column can help identify active alarms and potentially correlate with response times or other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kisG47NiS-lq"
   },
   "source": [
    "### Volunteer availability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZyJdYn1NTH8P",
    "outputId": "1f7e2986-e102-4b8f-ba0f-ad2474e93a9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from data/VolunteerAvailability.txt.\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2879387 entries, 0 to 2879386\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Dtype \n",
      "---  ------                ----- \n",
      " 0   userid                int64 \n",
      " 1   FromHour              int64 \n",
      " 2   FromMin               int64 \n",
      " 3   ToHour                int64 \n",
      " 4   ToMin                 int64 \n",
      " 5   AvailableWeekDay      int64 \n",
      " 6   AvailabilityLocation  int64 \n",
      " 7   CreatedDate           object\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 175.7+ MB\n",
      "None\n",
      "First 5 rows of the DataFrame:\n",
      "                userid  FromHour  FromMin  ToHour  ToMin  AvailableWeekDay  \\\n",
      "0  2210044967363094894         0        0      23     59                 0   \n",
      "1  2210044967363094894         0        0      23     59                 1   \n",
      "2  2210044967363094894         0        0      23     59                 2   \n",
      "3  2210044967363094894         0        0      23     59                 3   \n",
      "4  2210044967363094894         0        0      23     59                 4   \n",
      "\n",
      "   AvailabilityLocation              CreatedDate  \n",
      "0                     0  2023-05-25 19:59:53.413  \n",
      "1                     0  2023-05-25 19:59:53.413  \n",
      "2                     0  2023-05-25 19:59:53.413  \n",
      "3                     0  2023-05-25 19:59:53.413  \n",
      "4                     0  2023-05-25 19:59:53.413  \n",
      "Missing Values in DataFrame:\n",
      "Series([], dtype: int64)\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "volunteer_availability = PreliminaryDataInspection('data/VolunteerAvailability.txt', sep='\\t')\n",
    "\n",
    "volunteer_availability.check_info()\n",
    "volunteer_availability.check_head()\n",
    "volunteer_availability.check_missing_values()\n",
    "volunteer_availability.check_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HvYZlDkTjUi",
    "outputId": "227af82b-447d-4066-f76c-50827f4284bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from data/Volunteers.txt.\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 246088 entries, 0 to 246087\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   userid         246088 non-null  int64 \n",
      " 1   DateOfBirth    246088 non-null  object\n",
      " 2   Latitude       246088 non-null  object\n",
      " 3   Longitude      246088 non-null  object\n",
      " 4   WorkLatitude   246088 non-null  object\n",
      " 5   WorkLongitude  246088 non-null  object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 11.3+ MB\n",
      "None\n",
      "First 5 rows of the DataFrame:\n",
      "                userid              DateOfBirth          Latitude  \\\n",
      "0 -4402443911528580314  1973-10-16 00:00:00.000         53,239679   \n",
      "1  4147689039375744256  1989-07-11 00:00:00.000        52,3007863   \n",
      "2 -7843085838038396722  1997-07-01 00:00:00.000  52,3327560424805   \n",
      "3 -1646437989330162528  1976-01-30 00:00:00.000  52,6543579101563   \n",
      "4  5678998634590506361  1962-05-14 00:00:00.000         52,061889   \n",
      "\n",
      "          Longitude      WorkLatitude     WorkLongitude  \n",
      "0          6,579022                 0                 0  \n",
      "1         4,6913535                 0                 0  \n",
      "2  5,54554843902588  52,3861045837402  5,20340538024902  \n",
      "3  4,83092164993286                 0                 0  \n",
      "4          4,920561                 0                 0  \n",
      "Missing Values in DataFrame:\n",
      "Series([], dtype: int64)\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "volunteers = PreliminaryDataInspection('data/Volunteers.txt', sep='\\t')\n",
    "\n",
    "volunteers.check_info()\n",
    "volunteers.check_head()\n",
    "volunteers.check_missing_values()\n",
    "volunteers.check_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KSm6bBqoXKG5"
   },
   "source": [
    "## Create a Unified Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "cKrwSf7XXJif",
    "outputId": "28433683-24b5-4c49-a5d6-5ff94facdf49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alarmid</th>\n",
       "      <th>userid</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>devices</th>\n",
       "      <th>Response</th>\n",
       "      <th>ResponseDate</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>alarmlocaltime</th>\n",
       "      <th>Latitude_x</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude_y</th>\n",
       "      <th>WorkLatitude</th>\n",
       "      <th>WorkLongitude</th>\n",
       "      <th>FromHour</th>\n",
       "      <th>FromMin</th>\n",
       "      <th>ToHour</th>\n",
       "      <th>ToMin</th>\n",
       "      <th>AvailableWeekDay</th>\n",
       "      <th>AvailabilityLocation</th>\n",
       "      <th>CreatedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78100</td>\n",
       "      <td>2210044967363094894</td>\n",
       "      <td>4</td>\n",
       "      <td>Sms</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51,9987411499023</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>2023-09-08 15:19:27.160</td>\n",
       "      <td>51,999415</td>\n",
       "      <td>...</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-25 19:59:53.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78100</td>\n",
       "      <td>2210044967363094894</td>\n",
       "      <td>4</td>\n",
       "      <td>Sms</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51,9987411499023</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>2023-09-08 15:19:27.160</td>\n",
       "      <td>51,999415</td>\n",
       "      <td>...</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-25 19:59:53.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78100</td>\n",
       "      <td>2210044967363094894</td>\n",
       "      <td>4</td>\n",
       "      <td>Sms</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51,9987411499023</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>2023-09-08 15:19:27.160</td>\n",
       "      <td>51,999415</td>\n",
       "      <td>...</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-25 19:59:53.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78100</td>\n",
       "      <td>2210044967363094894</td>\n",
       "      <td>4</td>\n",
       "      <td>Sms</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51,9987411499023</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>2023-09-08 15:19:27.160</td>\n",
       "      <td>51,999415</td>\n",
       "      <td>...</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-25 19:59:53.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>78100</td>\n",
       "      <td>2210044967363094894</td>\n",
       "      <td>4</td>\n",
       "      <td>Sms</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51,9987411499023</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>2023-09-08 15:19:27.160</td>\n",
       "      <td>51,999415</td>\n",
       "      <td>...</td>\n",
       "      <td>4,77543687820435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2023-05-25 19:59:53.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   alarmid               userid  DeviceType devices  Response ResponseDate  \\\n",
       "0    78100  2210044967363094894           4     Sms         0          NaN   \n",
       "1    78100  2210044967363094894           4     Sms         0          NaN   \n",
       "2    78100  2210044967363094894           4     Sms         0          NaN   \n",
       "3    78100  2210044967363094894           4     Sms         0          NaN   \n",
       "4    78100  2210044967363094894           4     Sms         0          NaN   \n",
       "\n",
       "           latitude         longitude           alarmlocaltime Latitude_x  \\\n",
       "0  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
       "1  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
       "2  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
       "3  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
       "4  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
       "\n",
       "   ...       Longitude_y  WorkLatitude WorkLongitude FromHour FromMin ToHour  \\\n",
       "0  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
       "1  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
       "2  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
       "3  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
       "4  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
       "\n",
       "  ToMin  AvailableWeekDay  AvailabilityLocation              CreatedDate  \n",
       "0  59.0               0.0                   0.0  2023-05-25 19:59:53.413  \n",
       "1  59.0               1.0                   0.0  2023-05-25 19:59:53.413  \n",
       "2  59.0               2.0                   0.0  2023-05-25 19:59:53.413  \n",
       "3  59.0               3.0                   0.0  2023-05-25 19:59:53.413  \n",
       "4  59.0               4.0                   0.0  2023-05-25 19:59:53.413  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.merge(alarm_response.df, alarms.df, on='alarmid', how='left')\n",
    "merged_data = pd.merge(merged_data, volunteers.df, on='userid', how='left')\n",
    "merged_data = pd.merge(merged_data, volunteer_availability.df, on='userid', how='left')\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame provided directly.\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48348212 entries, 0 to 48348211\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   alarmid               int64  \n",
      " 1   userid                int64  \n",
      " 2   DeviceType            int64  \n",
      " 3   devices               object \n",
      " 4   Response              int64  \n",
      " 5   ResponseDate          object \n",
      " 6   latitude              object \n",
      " 7   longitude             object \n",
      " 8   alarmlocaltime        object \n",
      " 9   Latitude_x            object \n",
      " 10  Longitude_x           object \n",
      " 11  AlarmStatus           int64  \n",
      " 12  DateOfBirth           object \n",
      " 13  Latitude_y            object \n",
      " 14  Longitude_y           object \n",
      " 15  WorkLatitude          object \n",
      " 16  WorkLongitude         object \n",
      " 17  FromHour              float64\n",
      " 18  FromMin               float64\n",
      " 19  ToHour                float64\n",
      " 20  ToMin                 float64\n",
      " 21  AvailableWeekDay      float64\n",
      " 22  AvailabilityLocation  float64\n",
      " 23  CreatedDate           object \n",
      "dtypes: float64(6), int64(5), object(13)\n",
      "memory usage: 8.6+ GB\n",
      "None\n",
      "First 5 rows of the DataFrame:\n",
      "   alarmid               userid  DeviceType devices  Response ResponseDate  \\\n",
      "0    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "1    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "2    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "3    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "4    78100  2210044967363094894           4     Sms         0          NaN   \n",
      "\n",
      "           latitude         longitude           alarmlocaltime Latitude_x  \\\n",
      "0  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
      "1  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
      "2  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
      "3  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
      "4  51,9987411499023  4,77543687820435  2023-09-08 15:19:27.160  51,999415   \n",
      "\n",
      "   ...       Longitude_y  WorkLatitude WorkLongitude FromHour FromMin ToHour  \\\n",
      "0  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
      "1  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
      "2  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
      "3  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
      "4  ...  4,77543687820435             0             0      0.0     0.0   23.0   \n",
      "\n",
      "  ToMin  AvailableWeekDay  AvailabilityLocation              CreatedDate  \n",
      "0  59.0               0.0                   0.0  2023-05-25 19:59:53.413  \n",
      "1  59.0               1.0                   0.0  2023-05-25 19:59:53.413  \n",
      "2  59.0               2.0                   0.0  2023-05-25 19:59:53.413  \n",
      "3  59.0               3.0                   0.0  2023-05-25 19:59:53.413  \n",
      "4  59.0               4.0                   0.0  2023-05-25 19:59:53.413  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Missing Values in DataFrame:\n",
      "devices                     2099\n",
      "ResponseDate            41615781\n",
      "DateOfBirth               169484\n",
      "Latitude_y                169484\n",
      "Longitude_y               169484\n",
      "WorkLatitude              169484\n",
      "WorkLongitude             169484\n",
      "FromHour                  173774\n",
      "FromMin                   173774\n",
      "ToHour                    173774\n",
      "ToMin                     173774\n",
      "AvailableWeekDay          173774\n",
      "AvailabilityLocation      173774\n",
      "CreatedDate               173774\n",
      "dtype: int64\n",
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "data = PreliminaryDataInspection(df=merged_data)\n",
    "\n",
    "data.check_info()\n",
    "data.check_head()\n",
    "data.check_missing_values()\n",
    "data.check_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUiGYrNiUih4"
   },
   "source": [
    "## DataPreprocessor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "IDASA42aUmcs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"\n",
    "    A class for handling data preprocessing tasks, including cleaning,\n",
    "    feature engineering, and preparation for analysis or modeling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df=None, file_path=None, sep=\",\"):\n",
    "        \"\"\"\n",
    "        Initializes the DataPreprocessor class.\n",
    "\n",
    "        Args:\n",
    "            df (pd.DataFrame): A DataFrame provided directly. Defaults to None.\n",
    "            file_path (str): Path to the data file (CSV). Defaults to None.\n",
    "            sep (str): Separator used in the file. Defaults to \",\".\n",
    "        \"\"\"\n",
    "        if df is not None:\n",
    "            if isinstance(df, pd.DataFrame):\n",
    "                self.df = df\n",
    "                print(\"DataFrame provided directly.\")\n",
    "            else:\n",
    "                raise ValueError(\"Provided data is not a valid DataFrame.\")\n",
    "        elif file_path is not None:\n",
    "            self.df = self.load_data(file_path, sep)\n",
    "        else:\n",
    "            raise ValueError(\"Either a DataFrame or file path must be provided.\")\n",
    "\n",
    "    def load_data(self, file_path, sep=\",\"):\n",
    "        \"\"\"\n",
    "        Loads a dataset from a file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the data file.\n",
    "            sep (str): Separator used in the file. Defaults to \",\".\n",
    "\n",
    "        Returns:\n",
    "            pd.DataFrame: Loaded DataFrame.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, sep=sep)\n",
    "            print(f\"Data successfully loaded from {file_path}.\")\n",
    "            return df\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"An error occurred while loading data: {e}\")\n",
    "\n",
    "    def handle_missing_values(self, threshold=50):\n",
    "        \"\"\"\n",
    "        Handles missing values by dropping columns with high percentages\n",
    "        of missing values and imputing remaining missing values.\n",
    "\n",
    "        Args:\n",
    "            threshold (float): Percentage threshold for dropping columns. Defaults to 50%.\n",
    "        \"\"\"\n",
    "        missing_percentage = (self.df.isnull().sum() / len(self.df)) * 100\n",
    "        print(\"Missing value percentages:\\n\", missing_percentage)\n",
    "\n",
    "        # Drop columns with missing values above the threshold\n",
    "        columns_to_drop = missing_percentage[missing_percentage > threshold].index\n",
    "        self.df.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "        print(f\"Columns dropped: {list(columns_to_drop)}\")\n",
    "\n",
    "        # Fill missing values in numeric columns with median\n",
    "        numeric_cols = self.df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        self.df[numeric_cols] = self.df[numeric_cols].fillna(self.df[numeric_cols].median())\n",
    "\n",
    "        # Fill missing values in categorical columns with \"Unknown\"\n",
    "        categorical_cols = self.df.select_dtypes(include=['object']).columns\n",
    "        self.df[categorical_cols] = self.df[categorical_cols].fillna(\"Unknown\")\n",
    "\n",
    "    def fix_data_types(self):\n",
    "        \"\"\"\n",
    "        Fixes data types by converting latitude/longitude to numeric\n",
    "        and converting date columns to datetime.\n",
    "        \"\"\"\n",
    "        # Fix latitude and longitude columns\n",
    "        lat_long_cols = ['latitude', 'longitude', 'Latitude_x', 'Longitude_x', 'Latitude_y', 'Longitude_y']\n",
    "        for col in lat_long_cols:\n",
    "            if col in self.df.columns:\n",
    "                # Replace commas with dots and non-numeric values with NaN\n",
    "                self.df[col] = (\n",
    "                    self.df[col]\n",
    "                    .replace(',', '.', regex=True)\n",
    "                    .apply(pd.to_numeric, errors='coerce')\n",
    "                )\n",
    "\n",
    "        # Convert date columns to datetime\n",
    "        date_cols = ['ResponseDate', 'alarmlocaltime', 'CreatedDate']\n",
    "        for col in date_cols:\n",
    "            if col in self.df.columns:\n",
    "                self.df[col] = pd.to_datetime(self.df[col], errors='coerce')\n",
    "\n",
    "    def remove_duplicates(self):\n",
    "        \"\"\"\n",
    "        Removes duplicate rows from the dataset.\n",
    "        \"\"\"\n",
    "        initial_rows = len(self.df)\n",
    "        self.df.drop_duplicates(inplace=True)\n",
    "        final_rows = len(self.df)\n",
    "        print(f\"Removed {initial_rows - final_rows} duplicate rows.\")\n",
    "\n",
    "    def scale_numeric_features(self, features):\n",
    "        \"\"\"\n",
    "        Scales numeric features using StandardScaler.\n",
    "\n",
    "        Args:\n",
    "            features (list): List of numeric feature column names to scale.\n",
    "        \"\"\"\n",
    "        scaler = StandardScaler()\n",
    "        self.df[features] = scaler.fit_transform(self.df[features])\n",
    "\n",
    "    def engineer_features(self):\n",
    "        \"\"\"\n",
    "        Performs feature engineering, such as deriving response time\n",
    "        and creating date-related features.\n",
    "        \"\"\"\n",
    "        if 'ResponseDate' in self.df.columns and 'alarmlocaltime' in self.df.columns:\n",
    "            self.df['response_time'] = (self.df['ResponseDate'] - self.df['alarmlocaltime']).dt.total_seconds() / 60\n",
    "\n",
    "        # Add new features based on dates\n",
    "        for col in ['ResponseDate', 'alarmlocaltime']:\n",
    "            if col in self.df.columns:\n",
    "                self.df[f\"{col}_year\"] = self.df[col].dt.year\n",
    "                self.df[f\"{col}_month\"] = self.df[col].dt.month\n",
    "                self.df[f\"{col}_day\"] = self.df[col].dt.day\n",
    "\n",
    "    def visualize_data(self, feature):\n",
    "        \"\"\"\n",
    "        Visualizes the distribution of a numeric feature.\n",
    "\n",
    "        Args:\n",
    "            feature (str): The feature to visualize.\n",
    "        \"\"\"\n",
    "        if feature in self.df.columns:\n",
    "            sns.histplot(self.df[feature], bins=50)\n",
    "            plt.title(f\"Distribution of {feature}\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Feature {feature} not found in the DataFrame.\")\n",
    "\n",
    "    def save_data(self, file_path):\n",
    "        \"\"\"\n",
    "        Saves the cleaned DataFrame to a CSV file.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to save the file.\n",
    "        \"\"\"\n",
    "        self.df.to_csv(file_path, index=False)\n",
    "        print(f\"Data saved to {file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 685
    },
    "id": "cWFx0grgVUKg",
    "outputId": "4e1d7016-e580-49ca-8479-8e653972112f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame provided directly.\n",
      "Missing value percentages:\n",
      " alarmid                 0.0\n",
      "userid                  0.0\n",
      "DeviceType              0.0\n",
      "devices                 0.0\n",
      "Response                0.0\n",
      "latitude                0.0\n",
      "longitude               0.0\n",
      "alarmlocaltime          0.0\n",
      "Latitude_x              0.0\n",
      "Longitude_x             0.0\n",
      "AlarmStatus             0.0\n",
      "DateOfBirth             0.0\n",
      "Latitude_y              0.0\n",
      "Longitude_y             0.0\n",
      "WorkLatitude            0.0\n",
      "WorkLongitude           0.0\n",
      "FromHour                0.0\n",
      "FromMin                 0.0\n",
      "ToHour                  0.0\n",
      "ToMin                   0.0\n",
      "AvailableWeekDay        0.0\n",
      "AvailabilityLocation    0.0\n",
      "CreatedDate             0.0\n",
      "dtype: float64\n",
      "Columns dropped: []\n"
     ]
    }
   ],
   "source": [
    "# Initialize the preprocessor with a DataFrame or file path\n",
    "preprocessor = DataPreprocessor(df=data.df)\n",
    "\n",
    "# Handle missing values\n",
    "preprocessor.handle_missing_values(threshold=50)\n",
    "\n",
    "# Fix data types\n",
    "preprocessor.fix_data_types()\n",
    "\n",
    "# Remove duplicates\n",
    "preprocessor.remove_duplicates()\n",
    "\n",
    "# Scale numeric features\n",
    "numeric_features = ['FromHour', 'ToHour', 'FromMin', 'ToMin', 'AvailableWeekDay', 'AvailabilityLocation']\n",
    "preprocessor.scale_numeric_features(numeric_features)\n",
    "\n",
    "# Engineer new features\n",
    "preprocessor.engineer_features()\n",
    "\n",
    "# Visualize a feature\n",
    "preprocessor.visualize_data('response_time')\n",
    "\n",
    "# Save the cleaned data\n",
    "preprocessor.save_data(\"data/cleaned_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
